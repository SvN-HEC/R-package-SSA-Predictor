# The empirical autocorrelation function: nomore white noise
acf(x)
# Set filter length: should be sufficiently large for filter weights to decay to zero
L<-50
# we can apply gamma to xt or epsilont: in the latter case we have to convolve gamma with the Wold-decomposition of xt
# For that purpose we have to compute the weights of the Wold-decomposition (MA-inversion) of the ARMA
xi<-c(1,ARMAtoMA(ar=a1,ma=b1,lag.max=L-1))
par(mfrow=c(1,1))
ts.plot(xi,main="Wold decomposition of ARMA(1,1")
# Note that we can replicate xt by relying on the MA-inversion (Wold-decomposition) of the ARMA:
x_wold<-filter(epsilon,xi,side=1)
ts.plot(cbind(x,x_wold),main="ARMA vs. Wold: both series overlap")
# Let's now compute the convolution filter
gamma_conv<-conv_two_filt_func(xi,gamma)$conv
ts.plot(gamma_conv,main="Target filter as applied to epsilont")
# This filter is not symmetric anymore!
# Let's check that the output of both filters match
# We here rely on the one-sided filters (since otherwise the filter function would shift the outputs differently)
y_sym<-filter(x,gamma,side=1)
y_conv<-filter(epsilon,gamma_conv,side=1)
# Perfect match
ts.plot(cbind(y_sym,y_conv),main="Target applied to xt overlaps convolved target applied to epsilont")
# Why do we transform the target filter by convolution?
# Four main purposes:
# 1. We can easily derive the MSE nowcast (or any forecast or backcast) by replacing future epsilont by their optimal MSE zero-forecast
# 2. we can apply the formula for ht in Wildi, M. (2024) https://doi.org/10.1007/s41549-024-00097-5 (because the expression assumes the data to be white noise)
# 3. We can easily derive the spectral density of the MSE predictor yt
# 4. We can easily compute its expected MSE
# Let's first derive the MSE nowcast
# We set epsilon_{t+3}=epsilon_{t+2}=epsilon_{t+1}=0 and obtain the truncated filter
# Note that we append zeroes in order to keep the length fixed at L
gamma_conv_mse<-c(gamma_conv[4:L],rep(0,3))
ts.plot(gamma_conv_mse,main="MSE filter as applied to epsilont")
# In general we would like the MSE filter as applied to xt (not epsilont). Very easy: just deconvolve gamma_mse from gamma_conv_mse
gamma_mse<-deconvolute_func(gamma_conv_mse,xi)$dec_filt
ts.plot(gamma_mse,main="MSE filter as applied to xt")
# Check that filter outputs are identical
y_mse<-filter(x,gamma_mse,side=1)
y_conv_mse<-filter(epsilon,gamma_conv_mse,side=1)
# Same output
ts.plot(cbind(y_conv_mse,y_mse),main="Optimal filter applied to xt is the same as convolved filter applied to epsilont")
# We can now proceed to comparisons of MSE and target
y_sym<-filter(x,gamma,side=2)
ts.plot(cbind(y_sym,y_mse),col=c("black","green"),lty=1:2,main="Target (black) vs MSE (green)")
abline(h=0)
# We can see that the MSE is slightly noisier. Let's compute the empirical holding times of both filters
compute_empirical_ht_func(y_sym)
compute_empirical_ht_func(y_mse)
# The MSE filter crosses the zero line more often than the target (excess of 'noisy' alarms)
# We can compare the empirical holding times to the expected ht, see Wildi, M. (2024) https://doi.org/10.1007/s41549-024-00097-5
#   In the long run, empirical numbers converge to expected numbers (in the absence of model misspecification)
# But these numbers do not seem to match
#   Random sample deviations cannot explain the mismatch since the  series are sufficiently long
compute_holding_time_func(gamma)$ht
compute_holding_time_func(gamma_mse)$ht
# Solution: We need to provide the convolved filters, as applied to epsilont in order to obtain the correct
#   expected ht (recall the second purpose of the convolved filters mentioned above)
compute_holding_time_func(gamma_conv)$ht
compute_holding_time_func(gamma_conv_mse)$ht
# We infer that MSE generates roughly 40% more crossings than the target ('false alarms') in the long run
# We see, also, that the MSE is right shifted relative to the target (lagging)
# Let's measure the shift at zero-crossings based on the tau statistic introduced in JBCY paper
# For that purpose we compare target and MSE
data_mat<-cbind(y_sym,y_mse)
# The following plot suggest a lead of the target (a lag of the MSE) of one time-unit
max_lead<-4
compute_min_tau_func(data_mat,max_lead)
# Next we can compute empirical and true expected mean-square errors
mean((y_sym-y_mse)^2,na.rm=T)
# True MSE (see example 1 for background)
sigma^2*sum(gamma_conv[1:3]^2)
# We can also compute the percentage MSE which sets the error in relation to the signal or target
sum(gamma_conv[1:3]^2)/sum(gamma_conv^2)
# The relative MSE, 17%, is smaller than in the previous example because xt is smoother than epsilont
# Therefeore, the MSE predictor has to solve an `easier' problem here
# SSA can address smoothness and timeliness issues (at cost of MSE), see tutorials 1-5
# To conclude we look at amplitude and phase-shift functions of the MSE-predictor
# In general we are interested in analyzing how the predictor-filter affects the data: how strong
#   is the noise suppression, how large a lag?
# Therefore we generally compute amplitude and shifts of gamma_mse (the filter applied to xt)
K<-600
amp_obj_mse<-amp_shift_func(K,as.vector(gamma_mse),F)
amp_mse<-amp_obj_mse$amp
shift_mse<-amp_obj_mse$shift
par(mfrow=c(2,1))
plot(amp_mse,type="l",axes=F,xlab="Frequency",ylab="",main="Amplitude of MSE filter",col="green",ylim=c(0,max(amp_mse)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
plot(shift_mse,type="l",axes=F,xlab="Frequency",ylab="",main="Shift MSE",col="green")
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
# We see that noise-leakage at higher frequencies is even more pronounced than in the previous example
#   This is because xt is smoother than epsilont and needs less smoothing by the predictor-filter
# As an effect, the lag (phase-shift in passband) is slightly smaller, though still close to one
# If we want to compute the spectral density of the predictor y_mse then we have to rely on gamma_conv_mse, the filter
#   applied to epsilont, because xt does not have a flat spectrum (but epsilont does)
par(mfrow=c(1,1))
amp_obj_mse<-amp_shift_func(K,as.vector(gamma_conv_mse),F)
amp_conv_mse<-amp_obj_mse$amp
plot(sigma^2*amp_conv_mse^2,type="l",axes=F,xlab="Frequency",ylab="",main="Spectral density of predictor",col="green",ylim=c(0,max(sigma^2*amp_conv_mse^2)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
# The spectrum is rather weak towards higher frequencies: besides the squaring effect (we look at the squared amplitude function),
amp_obj_xi<-amp_shift_func(K,as.vector(xi),F)
amp_obj_mse
amp_obj_xi<-amp_shift_func(K,as.vector(xi),F)
amp_arma<-amp_obj_mse$amp
par(mfrow=c(1,1))
plot(amp_arma,type="l",axes=F,xlab="Frequency",ylab="",main="Amplitude of ARMA filter",col="green",ylim=c(0,max(amp_arma)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
par(mfrow=c(1,1))
amp_obj_mse<-amp_shift_func(K,as.vector(gamma_conv_mse),F)
amp_conv_mse<-amp_obj_mse$amp
plot(sigma^2*amp_conv_mse^2,type="l",axes=F,xlab="Frequency",ylab="",main="Spectral density of predictor",col="green",ylim=c(0,max(sigma^2*amp_conv_mse^2)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
amp_obj_xi<-amp_shift_func(K,as.vector(xi),F)
amp_arma<-amp_obj_xi$amp
par(mfrow=c(1,1))
plot(amp_arma,type="l",axes=F,xlab="Frequency",ylab="",main="Amplitude of ARMA filter",col="green",ylim=c(0,max(amp_arma)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
rm(list=ls())
# Load all relevant SSA-functions
source(paste(getwd(),"/R/simple_sign_accuracy.r",sep=""))
# Load tau-statistic: quantifies time-shift performances (lead/lag)
source(paste(getwd(),"/R/Tau_statistic.r",sep=""))
# Load signal extraction functions used for JBCY paper (relies on mFilter)
source(paste(getwd(),"/R/HP_JBCY_functions.r",sep=""))
#----------------------------------------------------------------
# Example 1: xt=epsilont white noise
# Assume the following symmetric target filter (gamma does not have to be symmetric, see tutorials 2-5)
gamma<-c(0.25,0.5,0.75,1,0.75,0.5,0.25)
# Symmetric target filter
plot(gamma,axes=F,type="l",xlab="Lag-structure",ylab="filter-coefficients",main="Simple signal extraction (smoothing) filter")
axis(1,at=1:length(gamma),labels=(-(length(gamma)+1)/2)+1:length(gamma))
axis(2)
box()
# Note that the above plot indicates that gamma is meant as a two-sided (acausal) filter
set.seed(231)
len<-120
# Scaling
sigma<-1
epsilon<-sigma*rnorm(len)
x<-epsilon
# No autocorrelation
acf(x)
y_sym<-filter(x,gamma,side=2)
y_one_sided<-filter(x,gamma,side=1)
tail(cbind(y_sym,y_one_sided))
ts.plot(cbind(y_sym,y_one_sided),col=c("black","black"),lty=1:2,main="One-sided vs. two-sided")
b_MSE<-gamma[((length(gamma)+1)/2):length(gamma)]
plot(b_MSE,axes=F,type="l",xlab="Lag-structure",ylab="filter-coefficients",main="MSE-nowcast filter")
axis(1,at=1:((length(gamma)+1)/2),labels=-1+1:((length(gamma)+1)/2))
axis(2)
box()
# We can now filter xt with this filter to obtain yt and compare the estimate yt and the target zt
# The filter is one-sided: side=1
y_mse<-filter(x,b_MSE,side=1)
y_sym<-filter(x,gamma,side=2)
ts.plot(cbind(y_sym,y_mse),col=c("black","green"),lty=1:2,main="Target (black) vs MSE (green)")
abline(h=0)
compute_empirical_ht_func(y_sym)
compute_empirical_ht_func(y_mse)
compute_holding_time_func(gamma)$ht
compute_holding_time_func(b_MSE)$ht
# We see also that the MSE is right shifted relative to the target (lagging)
# Let's measure the shift at zero-crossings based on the tau statistic introduced in JBCY paper
# For that purpose we compare target and MSE
data_mat<-cbind(y_sym,y_mse)
max_lead<-4
compute_min_tau_func(data_mat,max_lead)
# Next, we can compute empirical and true or expected mean-square error
mean((y_sym-y_mse)^2,na.rm=T)
# a. Weights assigned to future innovations by symmetric filter
gamma[1:3]
# b. MSE
sigma^2*sum(gamma[1:3]^2)
# We can also compute the percentage MSE which sets the error in relation to the signal or target
sum(gamma[1:3]^2)/sum(gamma^2)
# To conclude, we can look at amplitude and phase-shift functions of the MSE-predictor
#   -The amplitude tells us something about noise suppression of the filter: a 'good' filter damps high-frequency components strongly
#   -The phase-shift informs about the lag (or lead) of the predictor: a good filter has a small shift
# Both functions can be computed easily with amp_shift_func
# For this we first specify the number of equidistant frequency ordinates in [0,pi] (we omit negative frequencies which are mirrored)
K<-600
amp_obj_mse<-amp_shift_func(K,as.vector(b_MSE),F)
amp_mse<-amp_obj_mse$amp
shift_mse<-amp_obj_mse$shift
par(mfrow=c(2,1))
plot(amp_mse,type="l",axes=F,xlab="Frequency",ylab="",main="Amplitude of MSE filter",col="green",ylim=c(0,max(amp_mse)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
plot(shift_mse,type="l",axes=F,xlab="Frequency",ylab="",main="Shift MSE",col="green")
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
# To conclude we derive the spectral density of the predictor y_mse
#   -Note that epsilont, the input of the MSE filter, has a flat spectral density
#   -The convolution theorem then implies that the spectral density of y_mse corresponds to the squared amplitude of b_MSE
par(mfrow=c(1,1))
plot(sigma^2*amp_mse^2,type="l",axes=F,xlab="Frequency",ylab="",main="Spectral density of MSE predictor",col="green",ylim=c(0,max(sigma^2*amp_mse^2)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
#######################################################################################################
######################################################################################################
# Example 2: xt=ARMA (not white noise anymore)
# Same target as above
gamma<-c(0.25,0.5,0.75,1,0.75,0.5,0.25)
# New series
set.seed(76)
len<-1200
# Specify ARMA parameters for the DGP (data generating process)
a1<-0.4
b1<-0.3
sigma<-1
epsilon<-sigma*rnorm(len)
x<-epsilon
# Let's do it by hand (without arima.sim)
for (i in 2:len)
{
x[i]<-a1*x[i-1]+epsilon[i]+b1*epsilon[i-1]
}
# The empirical autocorrelation function: nomore white noise
acf(x)
# we can apply gamma to xt or epsilont: in the latter case we have to convolve gamma with the Wold-decomposition of xt
# For that purpose we have to compute the weights of the Wold-decomposition (MA-inversion) of the ARMA
xi<-c(1,ARMAtoMA(ar=a1,ma=b1,lag.max=L-1))
L<-50
# we can apply gamma to xt or epsilont: in the latter case we have to convolve gamma with the Wold-decomposition of xt
# For that purpose we have to compute the weights of the Wold-decomposition (MA-inversion) of the ARMA
xi<-c(1,ARMAtoMA(ar=a1,ma=b1,lag.max=L-1))
par(mfrow=c(1,1))
ts.plot(xi,main="Wold decomposition of ARMA(1,1")
# Note that we can replicate xt by relying on the MA-inversion (Wold-decomposition) of the ARMA:
x_wold<-filter(epsilon,xi,side=1)
ts.plot(cbind(x,x_wold),main="ARMA vs. Wold: both series overlap")
cbind(x,x_wold)
# Let's now compute the convolution filter
gamma_conv<-conv_two_filt_func(xi,gamma)$conv
ts.plot(gamma_conv,main="Target filter as applied to epsilont")
# Let's check that the output of both filters match
# We here rely on the one-sided filters (since otherwise the filter function would shift the outputs differently)
y_sym<-filter(x,gamma,side=1)
y_conv<-filter(epsilon,gamma_conv,side=1)
# Perfect match
ts.plot(cbind(y_sym,y_conv),main="Target applied to xt overlaps convolved target applied to epsilont")
# Let's first derive the MSE nowcast
# We set epsilon_{t+3}=epsilon_{t+2}=epsilon_{t+1}=0 and obtain the truncated filter
# Note that we append zeroes in order to keep the length fixed at L
gamma_conv_mse<-c(gamma_conv[4:L],rep(0,3))
ts.plot(gamma_conv_mse,main="MSE filter as applied to epsilont")
gamma_mse<-deconvolute_func(gamma_conv_mse,xi)$dec_filt
ts.plot(gamma_mse,main="MSE filter as applied to xt")
y_mse<-filter(x,gamma_mse,side=1)
y_conv_mse<-filter(epsilon,gamma_conv_mse,side=1)
# Same output
ts.plot(cbind(y_conv_mse,y_mse),main="Optimal filter applied to xt is the same as convolved filter applied to epsilont")
y_sym<-filter(x,gamma,side=2)
ts.plot(cbind(y_sym,y_mse),col=c("black","green"),lty=1:2,main="Target (black) vs MSE (green)")
abline(h=0)
compute_empirical_ht_func(y_sym)
compute_empirical_ht_func(y_mse)
# We can compare the empirical holding times to the expected ht, see Wildi, M. (2024) https://doi.org/10.1007/s41549-024-00097-5
#   In the long run, empirical numbers converge to expected numbers (in the absence of model misspecification)
# But these numbers do not seem to match
#   Random sample deviations cannot explain the mismatch since the  series are sufficiently long
compute_holding_time_func(gamma)$ht
compute_holding_time_func(gamma_mse)$ht
compute_holding_time_func(gamma_conv)$ht
compute_holding_time_func(gamma_conv_mse)$ht
# We see, also, that the MSE is right shifted relative to the target (lagging)
# Let's measure the shift at zero-crossings based on the tau statistic introduced in JBCY paper
# For that purpose we compare target and MSE
data_mat<-cbind(y_sym,y_mse)
# The following plot suggest a lead of the target (a lag of the MSE) of one time-unit
max_lead<-4
compute_min_tau_func(data_mat,max_lead)
# Next we can compute empirical and true expected mean-square errors
mean((y_sym-y_mse)^2,na.rm=T)
# True MSE (see example 1 for background)
sigma^2*sum(gamma_conv[1:3]^2)
# We can also compute the percentage MSE which sets the error in relation to the signal or target
sum(gamma_conv[1:3]^2)/sum(gamma_conv^2)
# The relative MSE, 17%, is smaller than in the previous example because xt is smoother than epsilont
# Therefeore, the MSE predictor has to solve an `easier' problem here
# SSA can address smoothness and timeliness issues (at cost of MSE), see tutorials 1-5
# To conclude we look at amplitude and phase-shift functions of the MSE-predictor
# In general we are interested in analyzing how the predictor-filter affects the data: how strong
#   is the noise suppression, how large a lag?
# Therefore we generally compute amplitude and shifts of gamma_mse (the filter applied to xt)
K<-600
amp_obj_mse<-amp_shift_func(K,as.vector(gamma_mse),F)
amp_mse<-amp_obj_mse$amp
shift_mse<-amp_obj_mse$shift
par(mfrow=c(2,1))
plot(amp_mse,type="l",axes=F,xlab="Frequency",ylab="",main="Amplitude of MSE filter",col="green",ylim=c(0,max(amp_mse)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
plot(shift_mse,type="l",axes=F,xlab="Frequency",ylab="",main="Shift MSE",col="green")
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
# If we want to compute the spectral density of the predictor y_mse then we have to rely on gamma_conv_mse, the filter
#   applied to epsilont, because xt does not have a flat spectrum (but epsilont does)
par(mfrow=c(1,1))
amp_obj_mse<-amp_shift_func(K,as.vector(gamma_conv_mse),F)
amp_conv_mse<-amp_obj_mse$amp
plot(sigma^2*amp_conv_mse^2,type="l",axes=F,xlab="Frequency",ylab="",main="Spectral density of predictor",col="green",ylim=c(0,max(sigma^2*amp_conv_mse^2)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
amp_obj_xi<-amp_shift_func(K,as.vector(xi),F)
amp_arma<-amp_obj_xi$amp
par(mfrow=c(1,1))
plot(amp_arma,type="l",axes=F,xlab="Frequency",ylab="",main="Amplitude of ARMA filter",col="green",ylim=c(0,max(amp_arma)))
abline(h=0)
axis(1,at=1+0:6*K/6,labels=expression(0, pi/6, 2*pi/6,3*pi/6,4*pi/6,5*pi/6,pi))
axis(2)
box()
# Set hyperparameters
# Holding time: we want SSA to replicate the MSE predictor: therefore we set ht accordingly
# We need the convolved filter (applied to epsilont) for inferring ht
ht<-compute_holding_time_func(gamma_conv_mse)$ht
# Instead of ht, we provide the bijective `twin', namely the lag-one acf, see Wildi, M. (2024) https://doi.org/10.1007/s41549-024-00097-5
# We can transform ht in rho1 with the function compute_rho_from_ht
rho1<-compute_rho_from_ht(ht)
rho1<-compute_holding_time_func(gamma_conv_mse)$rho_ff1
# Filter length (should be at least twice the holding time)
L<-max(L,2*round(ht,0))
# Nowcast i.e. delta=0
delta<-0
# Recall that the (symmetric, two-sided) target gamma is right-sifted by (length(gamma)-1)/2=3 time units: it is a one-sided causal filter
# In order to obtain the two-sided acausal target we have to left-shift gamma by (length(gamma)-1)/2 lags or,
#   stated otherwise, to forecast the causal gamma by (length(gamma)-1)/2+delta steps ahead
forecast_horizon<-(length(gamma)-1)/2+delta
forecast_horizon
forecast_horizon
# We let SSA know that the data is an ARMA: recall that the ARMA-filter pre-whitens the noise (it's a lowpass)
xi<-xi
# Target: symmetric (one-sided) filter: this will be shifted by forecast_horizon in SSA_func
# This is the filter applied to xt (not epsilont)
gammak_generic<-gamma
# Apply SSA
# Since gamma is applied to xt, we have to supply information about the link between xt and epsilont in terms of xi
# Warning messages inform that zeroes are appended to shorter filters and that SSA solution is very close to MSE after optimization
SSA_obj<-SSA_func(L,forecast_horizon,gammak_generic,rho1,xi)
# Filter as applied to xt
ssa_x<-SSA_obj$ssa_x
# Convolved filter as applied to epsilont
ssa_eps<-SSA_obj$ssa_eps
mplot<-cbind(ssa_x,gamma_mse)
plot(mplot[,1],main="Optimally scaled SSA and original MSE as applied to xt: SSA replicates MSE",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
# Same for the convolved designs (filters applied to epsilont)
ssa_eps=SSA_obj$ssa_eps
mplot<-cbind(ssa_eps,gamma_conv_mse)
# Both filters overlap: SSA just replicated MSE up to arbitrary scaling
plot(mplot[,1],main="Optimally scaled SSA and original MSE as applied to epsilont: SSA replicates MSE",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
# SSA also computes the MSE-filters directly: as applied to xt and epsilont
mplot<-cbind(SSA_obj$mse_x,gamma_mse)
# Both filters overlap: SSA just replicated MSE up to arbitrary scaling
plot(mplot[,1],main="MSE by SSA and original MSE as applied to xt: both filters overlap",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
# MSE as applied to epsilont
mplot<-cbind(SSA_obj$mse_eps,gamma_conv_mse)
# Both filters overlap: SSA just replicated MSE up to arbitrary scaling
plot(mplot[,1],main="MSE by SSA and original MSE as applied to epsilont: both filters overlap",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
# A. Criterion values:
# 1. Maximize the correlation with the MSE solution (here gamma_conv_mse) or
# 2. Maximize the correlation with the effective target (here the two sided filter)
# Both criteria are equivalent, see Wildi, M. (2024) https://doi.org/10.1007/s41549-024-00097-5
# Let's compute the first one:
#   We can rely on the convolved filters (applied to epsilont) to compute correlations
#   Assuming white noise, the exact formula for the cross-correlation is
t(ssa_eps)%*%gamma_conv_mse/sqrt(t(ssa_eps)%*%ssa_eps*t(gamma_conv_mse)%*%gamma_conv_mse)
# SSA returns this criterion value
SSA_obj$crit_rhoyz
# The second criterion: maximize correlation with two-sided target
#   We just have to correct for the different squared lengths (or variances) of MSE and two-sided target, see Wildi, M. (2024) https://doi.org/10.1007/s41549-024-00097-5
#   Since this ratio is independent of ssa_eps both criteria are equivalent (up to scaling)
length_ratio<-sqrt(sum(gamma_conv_mse^2)/sum(gamma_conv^2))
t(ssa_eps)%*%gamma_conv_mse/sqrt(t(ssa_eps)%*%ssa_eps*t(gamma_conv_mse)%*%gamma_conv_mse)*length_ratio
# SSA also returns the corresponding criterion value
SSA_obj$crit_rhoy_target
# We can verify pertinence of the above criterion values by computing empirical correlations
y_ssa<-filter(x,ssa_x,side=1)
# First criterion
cor(na.exclude(cbind(y_mse,y_ssa)))[1,2]
# Second criterion
cor(na.exclude(cbind(y_sym,y_ssa)))[1,2]
# We imposed
ht
# This ht corresponds to the lag-one ACF
rho1
# After optimization, SSA achieves
SSA_obj$crit_rhoyy
# Let's now check holding-times
# We can rely on the function compute_holding_time_func:
compute_holding_time_func(ssa_eps)$ht
# Indeed, the filter as applied to xt has a substantially smaller ht
compute_holding_time_func(ssa_x)$ht
compute_holding_time_func(xi)$ht
acf(na.exclude(y_ssa))$acf[2]
rho1
# Let's have a look at the empirical ht
compute_empirical_ht_func(y_ssa)
# It matches our constraint (error can be made arbitrarily small when increasing the sample size)
ht
# Example 4: alternative target specifications
# We copy example 3 but we exchange the symmetric filter for the MSE-filter in the target specification, see Wildi, M. (2024) https://doi.org/10.1007/s41549-024-00097-5
# We can supply either gamma_mse (as applied to xt) or gamma_conv_mse (as applied to epsilont)
#   But we must be careful when doing so...
# A. First case: gamma_mse the MSE filter applied to xt
gammak_generic<-gamma_mse
# This target is causal and does not have to be shifted (in contrast to gamma in exercise 3). We set:
forecast_horizon<-delta
forecast_horizon
# Since gamma_mse is applied to xt, we have to supply information about the link between xt and epsilont in terms of xi
xi<-xi
# Don't forget xi in the function call: otherwise SSA assumes xt=epsilont white noise, by default
SSA_obj<-SSA_func(L,forecast_horizon,gammak_generic,rho1,xi)
ssa_x=SSA_obj$ssa_x
mse_x<-SSA_obj$mse_x
mplot<-cbind(ssa_x,gamma_mse)
plot(mplot[,1],main="Optimally scaled SSA and original MSE as applied to xt: SSA replicates MSE",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
mplot<-cbind(ssa_eps,gamma_conv_mse)
plot(mplot[,1],main="Optimally scaled SSA and original MSE as applied to epsilont: SSA replicates MSE",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
gammak_generic<-gamma_conv_mse
# There is a subtle change in the function-call since we now omit xi
# By default (omission of xi), SSA assumes the data to be white noise
# This is correct since gamma_conv_mse is the convolved target and is applied to epsilont
SSA_obj<-SSA_func(L,forecast_horizon,gammak_generic,rho1)
ssa_x=SSA_obj$ssa_x
ssa_eps=SSA_obj$ssa_eps
mplot<-cbind(ssa_eps,gamma_conv_mse)
plot(mplot[,1],main="Optimally scaled SSA and original MSE as applied to xt: SSA replicates MSE",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
# Since we assume xt=epsilont (white noise) ssa_x and ssa_eps are identical in this case
mplot<-cbind(ssa_x,gamma_conv_mse)
plot(mplot[,1],main="Optimally scaled SSA and original MSE as applied to epsilont: SSA replicates MSE",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
# We could obtain the same result as above by setting
xi_null<-NULL
SSA_obj<-SSA_func(L,forecast_horizon,gammak_generic,rho1,xi_null)
ssa_x=SSA_obj$ssa_x
ssa_eps=SSA_obj$ssa_eps
mplot<-cbind(ssa_eps,gamma_conv_mse)
plot(mplot[,1],main="Optimally scaled SSA and original MSE as applied to xt: SSA replicates MSE",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
# Or we could obtain the same result by specifying the identity
xi_id<-1
SSA_obj<-SSA_func(L,forecast_horizon,gammak_generic,rho1,xi_id)
ssa_x=SSA_obj$ssa_x
ssa_eps=SSA_obj$ssa_eps
# We do not have to re-scale the new filter
mplot<-cbind(ssa_eps,gamma_conv_mse)
plot(mplot[,1],main="Optimally scaled SSA and original MSE as applied to xt: SSA replicates MSE",axes=F,type="l",xlab="Lag-structure",ylab="filter-weights")
lines(mplot[,2])
axis(1,at=1:L,labels=-1+1:L)
axis(2)
box()
